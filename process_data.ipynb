{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a8337fcf7eb2f01"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-16T10:49:27.971204Z",
     "start_time": "2024-11-16T10:48:18.906996Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/31/9e/6ebb433de864a6cd45716af52a4d7a8c3c9aaf3a98368e61db9e69e69a9c/pandas-2.2.3-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Obtaining dependency information for numpy>=1.22.4 from https://files.pythonhosted.org/packages/8e/8b/1c131ab5a94c1086c289c6e1da1d843de9dbd95fe5f5ee6e61904c9518e2/numpy-2.1.3-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached numpy-2.1.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nessm\\hdhtest\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/11/c3/005fcca25ce078d2cc29fd559379817424e94885510568bc1bc53d7d5846/pytz-2024.2-py2.py3-none-any.whl.metadata\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/a6/ab/7e5f53c3b9d14972843a647d8d7a853969a58aecc7559cb3267302c94774/tzdata-2024.2-py2.py3-none-any.whl.metadata\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nessm\\hdhtest\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Using cached numpy-2.1.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.1.3 pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        person_source_value  year_of_birth  gender_concept_id  month_of_birth  \\\n0   DPXX:00000000000000001X           1963                  2              12   \n1     DPXX:000000000000002X           1971                  1               2   \n2     DPXX:000000000000003X           1962                  1              12   \n3     DPXX:000000000000004X           1959                  2               3   \n4     DPXX:000000000000005X           1998                  1               4   \n5     DPXX:000000000000006X           1958                  1              11   \n6     DPXX:000000000000007X           1957                  2              12   \n7     DPXX:000000000000008X           1964                  1              11   \n8     DPXX:000000000000009X           1988                  1               7   \n9     DPXX:000000000000010X           1965                  2               3   \n10    DPXX:000000000000011X           1954                  1               1   \n11    DPXX:000000000000012X           1987                  2               5   \n12    DPXX:000000000000013X           1981                  2               6   \n13    DPXX:000000000000014X           1977                  1               8   \n14    DPXX:000000000000015X           1966                  2              11   \n15    DPXX:000000000000016X           1994                  1               5   \n16    DPXX:000000000000017X           1954                  2               2   \n17    DPXX:000000000000018X           1980                  1               4   \n18    DPXX:000000000000019X           1950                  2               7   \n19    DPXX:000000000000020X           1965                  2               2   \n\n    person_id  location_id  \n0           0            1  \n1           1            2  \n2           2            2  \n3           3            3  \n4           4            2  \n5           5            4  \n6           6            1  \n7           7            5  \n8           8            6  \n9           9            7  \n10         10            5  \n11         11            1  \n12         12            1  \n13         13            2  \n14         14            8  \n15         15            8  \n16         16            6  \n17         17            7  \n18         18            8  \n19         19            3  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>person_source_value</th>\n      <th>year_of_birth</th>\n      <th>gender_concept_id</th>\n      <th>month_of_birth</th>\n      <th>person_id</th>\n      <th>location_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DPXX:00000000000000001X</td>\n      <td>1963</td>\n      <td>2</td>\n      <td>12</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DPXX:000000000000002X</td>\n      <td>1971</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DPXX:000000000000003X</td>\n      <td>1962</td>\n      <td>1</td>\n      <td>12</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DPXX:000000000000004X</td>\n      <td>1959</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DPXX:000000000000005X</td>\n      <td>1998</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DPXX:000000000000006X</td>\n      <td>1958</td>\n      <td>1</td>\n      <td>11</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DPXX:000000000000007X</td>\n      <td>1957</td>\n      <td>2</td>\n      <td>12</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>DPXX:000000000000008X</td>\n      <td>1964</td>\n      <td>1</td>\n      <td>11</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>DPXX:000000000000009X</td>\n      <td>1988</td>\n      <td>1</td>\n      <td>7</td>\n      <td>8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DPXX:000000000000010X</td>\n      <td>1965</td>\n      <td>2</td>\n      <td>3</td>\n      <td>9</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DPXX:000000000000011X</td>\n      <td>1954</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>DPXX:000000000000012X</td>\n      <td>1987</td>\n      <td>2</td>\n      <td>5</td>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>DPXX:000000000000013X</td>\n      <td>1981</td>\n      <td>2</td>\n      <td>6</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>DPXX:000000000000014X</td>\n      <td>1977</td>\n      <td>1</td>\n      <td>8</td>\n      <td>13</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DPXX:000000000000015X</td>\n      <td>1966</td>\n      <td>2</td>\n      <td>11</td>\n      <td>14</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DPXX:000000000000016X</td>\n      <td>1994</td>\n      <td>1</td>\n      <td>5</td>\n      <td>15</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DPXX:000000000000017X</td>\n      <td>1954</td>\n      <td>2</td>\n      <td>2</td>\n      <td>16</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>DPXX:000000000000018X</td>\n      <td>1980</td>\n      <td>1</td>\n      <td>4</td>\n      <td>17</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>DPXX:000000000000019X</td>\n      <td>1950</td>\n      <td>2</td>\n      <td>7</td>\n      <td>18</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>DPXX:000000000000020X</td>\n      <td>1965</td>\n      <td>2</td>\n      <td>2</td>\n      <td>19</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le fichier source\n",
    "persons_df = pd.read_csv(\"./ir_ben_r.csv\")\n",
    "persons_df['person_id'] = persons_df.index\n",
    "\n",
    "# Renommer les colonnes pour correspondre aux noms standardis√©s\n",
    "persons_df.rename(columns={\n",
    "    \"NUM_ENQ\": \"person_source_value\",\n",
    "    \"ben_nai_ann\": \"year_of_birth\",\n",
    "    \"ben_nai_moi\": \"month_of_birth\",\n",
    "    \"ben_sex_cod\": \"gender_concept_id\"\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cr√©er une table Location en extrayant les informations de la table Person\n",
    "location_df = persons_df[['ben_res_dpt', 'ben_res_reg']].drop_duplicates().reset_index(drop=True)\n",
    "location_df['location_id'] = location_df.index + 1  # Assignation d'un ID unique pour chaque ligne\n",
    "\n",
    "persons_df = pd.merge(persons_df, location_df, how='left', on=['ben_res_dpt', 'ben_res_reg'])\n",
    "new_persons_df=persons_df[[\"person_source_value\",\"year_of_birth\",\"gender_concept_id\",\"month_of_birth\",\"person_id\",\"location_id\"]]\n",
    "\n",
    "\n",
    "location_df.rename(columns={\n",
    "    \"ben_res_reg\" : \"state\" ,\n",
    "     \"ben_res_dpt\": \"address_1\",\n",
    "}, inplace=True) \n",
    "# Sauvegarder le r√©sultat\n",
    "new_persons_df.to_csv(\"./Person.csv\", index=False) \n",
    "location_df.to_csv(\"./Location.csv\", index=False) \n",
    "\n",
    "new_persons_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T10:53:12.207798Z",
     "start_time": "2024-11-16T10:53:12.096682Z"
    }
   },
   "id": "dfb4342921e77b1b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table care_site cr√©√©e avec succ√®s.\n",
      "Donn√©es ins√©r√©es avec succ√®s dans la table care_site.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement sqlite3 (from versions: none)\n",
      "ERROR: No matching distribution found for sqlite3\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "data": {
      "text/plain": "   care_site_source_value                 care_site_name  care_site_id  \\\n0               750300360  l'H√¥pital Priv√© des Peupliers             0   \n1               750023772            Pharmacie Plaisance             1   \n\n  location_id  \n0        None  \n1        None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>care_site_source_value</th>\n      <th>care_site_name</th>\n      <th>care_site_id</th>\n      <th>location_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>750300360</td>\n      <td>l'H√¥pital Priv√© des Peupliers</td>\n      <td>0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>750023772</td>\n      <td>Pharmacie Plaisance</td>\n      <td>1</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install sqlite3\n",
    "import sqlite3\n",
    "\n",
    "care_sites = pd.read_csv(\"./t_mcoaae.csv\")\n",
    "\n",
    "care_sites['care_site_id'] = care_sites.index\n",
    "\n",
    "\"\"\"Comme la colonne soc_rai correspond au nom de l'√©tablissement dans le fichier et non √† la raison sociale comme indiqu√© dans la documentation ATHENA, je l'ai donc consid√©r√©e comme une erreur et j'ai l'utilis√© comme le nom de l'√©tablissement.\"\"\"\n",
    "\n",
    "care_sites.rename(columns={\"eta_num\": \"care_site_source_value\",\"soc_rai\":\"care_site_name\"}, inplace=True)\n",
    "\n",
    "# Ajouter des colonnes vides pour care_site_name et location_id\n",
    "care_sites[\"location_id\"] = None\n",
    "\n",
    "# Connexion √† la base de donn√©es SQLite\n",
    "conn = sqlite3.connect(\"healthcare.db\")  # Nom de la base de donn√©es\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# V√©rifier si la table existe d√©j√†, sinon la cr√©er\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='care_site';\")\n",
    "table_exists = cursor.fetchone()\n",
    "\n",
    "if not table_exists:\n",
    "    # Cr√©ation de la table care_site si elle n'existe pas d√©j√†\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE care_site (\n",
    "        care_site_id INTEGER PRIMARY KEY,      \n",
    "        care_site_name TEXT,                       \n",
    "        location_id INTEGER,                      \n",
    "        care_site_source_value TEXT             \n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    print(\"Table care_site cr√©√©e avec succ√®s.\")\n",
    "else:\n",
    "    print(\"La table care_site existe d√©j√†.\")\n",
    "    \n",
    "# Ins√©rer les donn√©es dans la table SQLite\n",
    "care_sites.to_sql(\"care_site\", conn, if_exists=\"append\", index=False)\n",
    "print(\"Donn√©es ins√©r√©es avec succ√®s dans la table care_site.\")\n",
    "\n",
    "# Fermer la connexion √† la base de donn√©es\n",
    "conn.close()\n",
    "care_sites"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T10:54:15.694127Z",
     "start_time": "2024-11-16T10:54:13.332184Z"
    }
   },
   "id": "f58255f3486ca8d4",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Using cached pyspark-3.5.3-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.7 (from pyspark)\n",
      "  Obtaining dependency information for py4j==0.10.9.7 from https://files.pythonhosted.org/packages/10/30/a58b32568f1623aaad7db22aa9eafc4c6c194b429ff35bdc55ca2726da47/py4j-0.10.9.7-py2.py3-none-any.whl.metadata\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.3\n",
      "+--------------------+----------------------+-----------+---------------------+\n",
      "|specialty_concept_id|specialty_source_value|provider_id|provider_source_value|\n",
      "+--------------------+----------------------+-----------+---------------------+\n",
      "|                  50|            Pharmacien|          0|                    0|\n",
      "|                  26|      Kin√©sith√©rapeute|          1|                    1|\n",
      "|                   1|   M√©decin g√©n√©raliste|          2|                    2|\n",
      "|                   6|            Radiologue|          3|                    3|\n",
      "+--------------------+----------------------+-----------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import monotonically_increasing_id, lit\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# Initialize SparkSession\n",
    "conf = SparkConf().set(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\")\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "# Read CSV file into PySpark DataFrame\n",
    "df1 = spark.read.csv(\"./ir_act_v.csv\", header=True, inferSchema=True)\n",
    "df2 = spark.read.csv(\"./ir_spe_v.csv\", header=True, inferSchema=True)\n",
    "# Process the DataFrame\n",
    "df1 = df1.withColumnRenamed(\"pfs_act_nat\", \"specialty_concept_id\") \\\n",
    "       .withColumnRenamed(\"label\", \"specialty_source_value\")\n",
    "\n",
    "df2 = df2.withColumnRenamed(\"pfs_spe_cod\", \"specialty_concept_id\") \\\n",
    "       .withColumnRenamed(\"label\", \"specialty_source_value\")\n",
    "\n",
    "merged_df = df1.union(df2)\n",
    "merged_df = merged_df.distinct()\n",
    "merged_df = merged_df.withColumn(\"provider_id\", monotonically_increasing_id())\n",
    "merged_df = merged_df.withColumn(\"provider_id\", merged_df[\"provider_id\"].cast(\"int\"))\n",
    "#I didnt find any information about provider_source_value so i decided to use the provider_id as a provider_source_value \n",
    "merged_df = merged_df.withColumn(\"provider_source_value\", merged_df[\"provider_id\"].cast(\"string\"))\n",
    "\n",
    "#merged_df.write.parquet(\"./provider.parquet\")\n",
    "merged_df.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T11:19:31.540448Z",
     "start_time": "2024-11-16T11:18:41.486001Z"
    }
   },
   "id": "37c67b32f8e594e3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2a658f2d44ff5d06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
